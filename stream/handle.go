package stream

import (
	"bufio"
	"context"
	"errors"
	"fmt"
	"github.com/qist/tvgate/auth"
	"github.com/qist/tvgate/logger"
	"net"
	"time"
	// "github.com/qist/tvgate/monitor"
	"io"
	"net/http"
	"net/url"
	"regexp"
	"strings"
	"sync"
	"path/filepath"

	"github.com/qist/tvgate/utils/buffer"
)

// å®šä¹‰ä»»åŠ¡ç»“æ„ä½“ç”¨äºsync.Pool
type handleTask struct {
	f func()
}

// åˆ›å»ºsync.Poolç”¨äºå¤ç”¨ä»»åŠ¡å¯¹è±¡
var handleTaskPool = sync.Pool{
	New: func() interface{} {
		return &handleTask{}
	},
}

// ç»Ÿä¸€å¤„ç†å“åº”ï¼ˆé‡å®šå‘ã€ç‰¹æ®Šç±»å‹ã€æ™®é€šå†…å®¹ï¼‰
func HandleProxyResponse(ctx context.Context, w http.ResponseWriter, r *http.Request, targetURL string, resp *http.Response, updateActive func()) {
	defer func() {
		if err := resp.Body.Close(); err != nil {
			logger.LogPrintf("å…³é—­å“åº”ä½“é”™è¯¯: %v", err)
		}
	}()

	logger.LogRequestAndResponse(r, targetURL, resp) // æ—¥å¿—è®°å½•

	contentType := resp.Header.Get("Content-Type")

	switch resp.StatusCode {
	case http.StatusMovedPermanently, http.StatusFound, http.StatusTemporaryRedirect:
		handleRedirect(w, r, resp)
		return
	}

	if IsSupportedContentType(contentType) {
		handleSpecialContent(w, r, resp, nil) // è¿™é‡Œä¸éœ€è¦bufï¼Œå› ä¸ºhandleSpecialContentå†…éƒ¨ä¼šè‡ªå·±è·å–
		return
	}

	// æ£€æŸ¥æ˜¯å¦ä¸ºTSè¯·æ±‚ï¼Œå¦‚æœæ˜¯ï¼Œéœ€è¦æå‰æ¸…ç†å¯èƒ½çš„é—®é¢˜å¤´éƒ¨
	u, err := url.Parse(targetURL)
	if err != nil {
		logger.LogPrintf("è§£æç›®æ ‡URLå¤±è´¥: %v", err)
		return
	}
	
	if strings.EqualFold(filepath.Ext(u.Path), ".ts") {
		// åˆ é™¤å¯èƒ½å¼•èµ·é—®é¢˜çš„å¤´éƒ¨ï¼Œç‰¹åˆ«æ˜¯Content-Length
		// è¿™å¿…é¡»åœ¨å†™å…¥ä»»ä½•å“åº”æ•°æ®ä¹‹å‰å®Œæˆ
		resp.Header.Del("Content-Length")
	}

	// å¤åˆ¶å“åº”å¤´
	CopyHeader(w.Header(), resp.Header, r.ProtoMajor)
	w.WriteHeader(resp.StatusCode)

	// è§£æURLå¹¶è·å–æœ€ä¼˜ç¼“å†²åŒºå¤§å°
	bufSize := buffer.GetOptimalBufferSize(contentType, u.Path)
	buf := buffer.GetBuffer(bufSize)
	defer buffer.PutBuffer(bufSize, buf)

	// ä½¿ç”¨ç»Ÿä¸€çš„å“åº”å¤åˆ¶å‡½æ•°
	copyFunc := func() error {
		return CopyResponse(ctx, w, r, resp, targetURL, buf, bufSize, updateActive, resp.StatusCode)
	}

	// ä½¿ç”¨ç»Ÿä¸€çš„æ‰§è¡Œå‡½æ•°å¤„ç†å¤åˆ¶æ“ä½œ
	executeCopyWithPool(ctx, r, targetURL, copyFunc, resp)
}

// executeCopyWithPool ä½¿ç”¨ä»»åŠ¡æ± æ‰§è¡Œå¤åˆ¶æ“ä½œ
func executeCopyWithPool(ctx context.Context, r *http.Request, targetURL string, copyFunc func() error, resp *http.Response) {
	done := make(chan struct{})

	// ä»æ± ä¸­è·å–ä»»åŠ¡å¯¹è±¡
	task := handleTaskPool.Get().(*handleTask)
	task.f = func() {
		defer close(done)
		if err := copyFunc(); err != nil {
			HandleCopyError(r, err, resp)
		}
	}

	// åœ¨goroutineå†…éƒ¨æ‰§è¡Œä»»åŠ¡å¹¶ç¡®ä¿å®Œæˆåæ”¾å›æ± ä¸­
	go func() {
		defer func() {
			// æ¸…ç©ºä»»åŠ¡å¹¶æ”¾å›æ± ä¸­
			task.f = nil
			handleTaskPool.Put(task)
		}()
		task.f()
	}()

	select {
	case <-ctx.Done():
		logger.LogPrintf("å®¢æˆ·ç«¯æ–­å¼€è¿æ¥: %s", targetURL)
	case <-done:
		logger.LogPrintf("å“åº”æˆåŠŸå®Œæˆ: %s", targetURL)
	}
}

// Copytext æµå¼å¤åˆ¶ src -> dstï¼Œä½¿ç”¨ buffer æ± ï¼Œbufio å†…éƒ¨ç¼“å­˜å¯æ§
func Copytext(ctx context.Context, dst io.Writer, src io.Reader, buf []byte, updateActive func()) error {
	// æ´»è·ƒæ—¶é—´å¿ƒè·³
	var activeTicker *time.Ticker
	if updateActive != nil {
		activeTicker = time.NewTicker(5 * time.Second)
		defer activeTicker.Stop()
		defer updateActive() // é€€å‡ºå‰æ›´æ–°ä¸€æ¬¡
	}

	// flush å®šæ—¶å™¨ï¼ˆé™ä½å»¶è¿Ÿï¼‰
	flushTicker := time.NewTicker(200 * time.Millisecond)
	defer flushTicker.Stop()

	// æ˜¯å¦æ”¯æŒ http flush
	flusher, canFlush := dst.(http.Flusher)

	// ç»Ÿè®¡å†™å…¥å­—èŠ‚æ•°
	bytesWritten := 0

	// å¦‚æœ src æ˜¯ net.Connï¼Œç»™å®ƒç»‘ ctx
	if c, ok := src.(net.Conn); ok {
		go func() {
			<-ctx.Done()
			// æ‰“æ–­é˜»å¡ read
			_ = c.SetReadDeadline(time.Now())
		}()
	}

	for {
		// è¯»å–æ•°æ®
		n, readErr := src.Read(buf)
		if n > 0 {
			// monitor.AddAppInboundBytes(uint64(n))
			written := 0
			for written < n {
				wn, writeErr := dst.Write(buf[written:n])
				if writeErr != nil {
					return fmt.Errorf("å†™å…¥é”™è¯¯: %w", writeErr)
				}
				written += wn
				bytesWritten += wn
			}
			// monitor.AddAppOutboundBytes(uint64(n))

			// å¤§æ•°æ®é‡è§¦å‘ flush
			if canFlush && bytesWritten >= 32*1024 {
				flusher.Flush()
				bytesWritten = 0
			}
		}

		// é”™è¯¯å¤„ç†
		if readErr != nil {
			if canFlush && bytesWritten > 0 {
				flusher.Flush()
			}
			if errors.Is(readErr, io.EOF) {
				return nil
			}
			return fmt.Errorf("è¯»å–é”™è¯¯: %w", readErr)
		}

		// éé˜»å¡æ£€æŸ¥ ctx / ticker
		select {
		case <-ctx.Done():
			return ctx.Err()
		case <-flushTicker.C:
			if canFlush && bytesWritten > 0 {
				flusher.Flush()
				bytesWritten = 0
			}
		case <-activeTicker.C:
			if updateActive != nil {
				updateActive()
			}
		default:
		}
	}
}

func isWebPageContent(contentType, path string) bool {
	ct := strings.ToLower(contentType)
	p := strings.ToLower(path)

	// å»æ‰å‚æ•°ï¼ˆ; charset=xxxï¼‰
	if i := strings.Index(ct, ";"); i != -1 {
		ct = ct[:i]
	}

	// ===== æ˜ç¡®æ’é™¤æµåª’ä½“ =====
	if strings.HasPrefix(ct, "video/") ||
		strings.HasPrefix(ct, "audio/") {
		return false
	}

	// ===== image ç‰¹åˆ¤ï¼šåªå…è®¸ svg =====
	if strings.HasPrefix(ct, "image/") {
		return ct == "image/svg+xml"
	}

	// ===== æ˜ç¡®å…è®¸çš„ Web / æ–‡æœ¬ç±»å‹ =====
	switch ct {
	case
		"text/html",
		"text/plain",
		"text/css",
		"text/markdown",

		"application/javascript",
		"application/x-javascript",
		"application/json",
		"application/xml",
		"application/xhtml+xml",
		"application/rss+xml",
		"application/atom+xml",

		"image/svg+xml",
		"application/wasm":
		return true
	}

	// ===== å¤„ç† pathï¼ˆå» query / fragmentï¼‰=====
	if i := strings.IndexAny(p, "?#"); i != -1 {
		p = p[:i]
	}

	// ===== æ‰©å±•åå…œåº• =====
	switch {
	case strings.HasSuffix(p, ".html"),
		strings.HasSuffix(p, ".htm"),
		strings.HasSuffix(p, ".css"),
		strings.HasSuffix(p, ".js"),
		strings.HasSuffix(p, ".mjs"),
		strings.HasSuffix(p, ".json"),
		strings.HasSuffix(p, ".xml"),
		strings.HasSuffix(p, ".txt"),
		strings.HasSuffix(p, ".md"),
		strings.HasSuffix(p, ".map"),
		strings.HasSuffix(p, ".svg"),
		strings.HasSuffix(p, ".wasm"):
		return true
	}

	return false
}

// getRequestScheme è¿”å›å®¢æˆ·ç«¯çœŸå®ä½¿ç”¨çš„åè®® (http/https)
func getRequestScheme(r *http.Request) string {
	// 1. å…ˆçœ‹æ ‡å‡†å¤´
	if proto := r.Header.Get("X-Forwarded-Proto"); proto != "" {
		return proto
	}

	// 2. Cloudflare ä¸“ç”¨å¤´
	if cfVisitor := r.Header.Get("CF-Visitor"); strings.Contains(cfVisitor, "https") {
		return "https"
	}

	// 3. æ ‡å‡† Forwarded å¤´
	if forwarded := r.Header.Get("Forwarded"); strings.Contains(forwarded, "proto=https") {
		return "https"
	}

	// 4. æ²¡æœ‰ä»£ç†å¤´å°±çœ‹åç«¯æ˜¯å¦å¯ç”¨ TLS
	if r.TLS != nil {
		return "https"
	}

	return "http"
}

// æ”¯æŒçš„å†…å®¹ç±»å‹åˆ—è¡¨
var supportedContentTypes = []string{
	"application/vnd.apple.mpegurl",
	"application/x-mpegurl",
	"audio/mpegurl",
	"audio/x-mpegurl",
	"application/mpegurl",
}

// æ£€æŸ¥å†…å®¹ç±»å‹æ˜¯å¦å—æ”¯æŒ
func IsSupportedContentType(contentType string) bool {
	contentType = strings.ToLower(contentType)
	for _, t := range supportedContentTypes {
		if strings.HasPrefix(contentType, strings.ToLower(t)) {
			return true
		}
	}
	return false
}

// getTargetPath è·å–ç›®æ ‡è·¯å¾„
func GetTargetPath(r *http.Request) string {
	return r.URL.Path[1:] // å»é™¤å¼€å¤´çš„ /
}

// getTargetURL è·å–å®Œæ•´çš„ç›®æ ‡URL
func GetTargetURL(r *http.Request, targetPath string) string {
	// åˆ†ç¦»è·¯å¾„å’ŒæŸ¥è¯¢å‚æ•°
	pathAndQuery := strings.SplitN(targetPath, "?", 2)
	path := pathAndQuery[0]
	var query string
	if len(pathAndQuery) > 1 {
		query = "?" + pathAndQuery[1]
	}

	// å¤„ç†URLè·¯å¾„éƒ¨åˆ†
	if strings.HasPrefix(path, "http:/") && !strings.HasPrefix(path, "http://") {
		path = "http://" + strings.TrimPrefix(path, "http:/")
	} else if strings.HasPrefix(path, "https:/") && !strings.HasPrefix(path, "https://") {
		path = "https://" + strings.TrimPrefix(path, "https:/")
	} else if !strings.HasPrefix(path, "http://") && !strings.HasPrefix(path, "https://") {
		path = "http://" + path
	}

	// é‡æ–°ç»„åˆè·¯å¾„å’ŒæŸ¥è¯¢å‚æ•°
	targetURL := path + query

	// ä¿ç•™åŸå§‹è¯·æ±‚ä¸­çš„æŸ¥è¯¢å‚æ•°
	if r.URL.RawQuery != "" {
		if strings.Contains(targetURL, "?") {
			targetURL += "&" + r.URL.RawQuery
		} else {
			targetURL += "?" + r.URL.RawQuery
		}
	}
	//logger.LogPrintf("getTargetURL å¤„ç†: åŸå§‹è·¯å¾„=%s, æŸ¥è¯¢å‚æ•°=%s, æœ€ç»ˆURL=%s",
	//	path, r.URL.RawQuery, targetURL)

	return targetURL
}


// CopyWithContext æ”¯æŒ HTTP hub æ¨¡å¼ï¼šæŒ‰åç«¯URLä¸ºé”®ï¼Œå•ä¸Šæ¸¸å¹¿æ’­åˆ°æ‰€æœ‰å‰ç«¯
func CopyWithContext(
	ctx context.Context,
	dst http.ResponseWriter,
	src io.Reader,
	buf []byte,
	bufSize int,
	updateActive func(),
	backendKey string,
	statusCode int,
) error {
	h := GetOrCreateHTTPHub(backendKey, statusCode)

	// æ£€æŸ¥æ˜¯å¦ä¸ºTSè¯·æ±‚ï¼Œä»¥å†³å®šå¤„ç†æ–¹å¼
	if h.IsTSRequest(backendKey) {
		key := normalizeCacheKey(backendKey)

		// å°è¯•ä»æµå¼ç¼“å­˜è·å–
		if GlobalTSCache != nil {
			if cacheItem, ok := GlobalTSCache.Get(key); ok {
				done := make(chan struct{})
				defer close(done)
				
				// å¯¹äºTSç¼“å­˜è¯»å–ï¼Œåˆ é™¤Content-Lengthå¤´éƒ¨ä»¥é¿å…é•¿åº¦ä¸åŒ¹é…é—®é¢˜
				if rw, ok := dst.(http.ResponseWriter); ok {
					rw.Header().Del("Content-Length")
				}
				
				// ä»ç¼“å­˜æµå¼è¯»å–å¹¶å†™å…¥å“åº”
				if err := cacheItem.ReadAll(dst, done); err != nil {
					// å®¢æˆ·ç«¯è¿æ¥å¯èƒ½å·²æ–­å¼€ï¼Œè®°å½•ä½†ä¸è§†ä¸ºé”™è¯¯
					if err != io.EOF {
						logger.LogPrintf("ä»ç¼“å­˜è¯»å–TSæ•°æ®æ—¶å‡ºé”™: %v", err)
					}
					return nil // å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ä¸æ˜¯æœåŠ¡å™¨é”™è¯¯
				}
				
				if f, ok := dst.(http.Flusher); ok {
					f.Flush()
				}
				return nil
			}
		}

		// ä½¿ç”¨singleflightç¡®ä¿ç›¸åŒURLåªè¿›è¡Œä¸€æ¬¡è·å–æ“ä½œ
		if GlobalTSCache != nil {
			_, err, _ := GlobalTSCache.sf.Do(key, func() (interface{}, error) {
				// åˆ›å»ºæ–°çš„æµå¼ç¼“å­˜é¡¹
				cacheItem, _ := GlobalTSCache.GetOrCreate(key)
				
				// ä»æºè¯»å–å¹¶åŒæ—¶å†™å…¥ç¼“å­˜å’Œå“åº”
				bufRead := make([]byte, 32*1024) // 32KB åˆ†ç‰‡
				for {
					n, err := src.Read(bufRead)
					if n > 0 {
						// å°†æ•°æ®å†™å…¥ç¼“å­˜
						chunk := make([]byte, n)
						copy(chunk, bufRead[:n])
						if GlobalTSCache != nil {
							GlobalTSCache.WriteChunkWithByteTracking(cacheItem, chunk)
						}

						// åŒæ—¶å†™å…¥å“åº”
						written, wErr := dst.Write(chunk)
						if wErr != nil {
							return nil, wErr
						}
						if written != n {
							return nil, io.ErrShortWrite
						}
						
						if f, ok := dst.(http.Flusher); ok {
							f.Flush()
						}
					}

					if err != nil {
						if err == io.EOF {
							return nil, nil
						}
						return nil, err
					}
				}
			})

			if err != nil {
				return err
			}
			
			return nil
		}

		client := h.AddClient(dst, bufSize)
		defer h.RemoveClient(client)

		// ä¼ é€’backendKeyä»¥åŒºåˆ†å¤„ç†æ–¹å¼
		h.EnsureProducer(ctx, src, buf)

		return client.WriteLoop(ctx, updateActive)
	}

	client := h.AddClient(dst, bufSize)
	defer h.RemoveClient(client)

	// ä¼ é€’backendKeyä»¥åŒºåˆ†å¤„ç†æ–¹å¼
	h.EnsureProducer(ctx, src, buf)

	return client.WriteLoop(ctx, updateActive)
}

func HandleCopyError(r *http.Request, err error, proxyResp *http.Response) {
	if errors.Is(err, context.Canceled) {
		logger.LogPrintf("ä¼ è¾“è¢«å–æ¶ˆ: %v, URL: %s", err, proxyResp.Request.URL.String())
	} else if errors.Is(err, context.DeadlineExceeded) {
		logger.LogPrintf("ä¼ è¾“è¶…æ—¶: %v, URL: %s", err, proxyResp.Request.URL.String())
	} else {
		logger.LogPrintf("[%s] å‰ç«¯å…³é—­è¿æ¥ %s", r.RemoteAddr, proxyResp.Request.URL.String())
	}

	// å¯é€‰ï¼šå‘å®¢æˆ·ç«¯è¿”å›é”™è¯¯
	// if w.Header().Get("Content-Length") == "" {
	// 	http.Error(w, "æœåŠ¡å™¨é”™è¯¯", http.StatusInternalServerError)
	// }
}

// copyHeadersExceptSensitive å¤åˆ¶ HTTP å¤´éƒ¨ï¼Œè·³è¿‡æ•æ„Ÿæˆ–ç‰¹æ®Šå¤´éƒ¨
func CopyHeadersExceptSensitive(dst http.Header, src http.Header, protoMajor int) {
	for k, vv := range src {
		lowerKey := strings.ToLower(k)
		// è·³è¿‡ä¸å…¼å®¹å¤´
		switch lowerKey {
		case "connection", "proxy-connection", "keep-alive",
			"transfer-encoding", "upgrade", "te", "trailer", "trailers":
			continue
		}
		// å¦‚æœæ˜¯ HTTP/2ï¼Œä¸å…è®¸ keep-alive ä¹‹ç±»
		if protoMajor == 2 && (lowerKey == "keep-alive" || lowerKey == "connection") {
			continue
		}
		for _, v := range vv {
			dst.Add(k, v)
		}
	}
}

// copyHeader å¤åˆ¶ HTTP å¤´éƒ¨ï¼ŒæŒ‰åè®®ç‰ˆæœ¬è¿‡æ»¤ä¸å…¼å®¹å­—æ®µ
// - dst: ç›®æ ‡ Headerï¼ˆå®¢æˆ·ç«¯æˆ–åç«¯ï¼‰
// - src: æ¥æº Headerï¼ˆåç«¯å“åº”æˆ–å®¢æˆ·ç«¯è¯·æ±‚ï¼‰
// - protoMajor: å®¢æˆ·ç«¯ä½¿ç”¨çš„åè®®ç‰ˆæœ¬ï¼Œ1 = HTTP/1.x, 2 = HTTP/2
func CopyHeader(dst, src http.Header, protoMajor int) {
	for k, vv := range src {
		lowerKey := strings.ToLower(k)

		// æ°¸è¿œä¸åº”è¯¥é€ä¼ çš„å¤´
		switch lowerKey {
		case "host", "proxy-authorization", "proxy-connection":
			continue
		}

		// HTTP/2 ä¸å…è®¸çš„å¤´
		if protoMajor == 2 {
			switch lowerKey {
			case "connection", "keep-alive", "transfer-encoding",
				"upgrade", "te", "trailer", "trailers":
				continue
			}
		}

		// å¤åˆ¶å‰©ä½™å¤´
		for _, v := range vv {
			dst.Add(k, v)
		}
	}
}

// handleRedirect å¤„ç† HTTP 301/302 é‡å®šå‘
func handleRedirect(w http.ResponseWriter, r *http.Request, proxyResp *http.Response) {
	location := proxyResp.Header.Get("Location")
	if location == "" {
		w.WriteHeader(proxyResp.StatusCode)
		return
	}

	logger.LogPrintf("å¤„ç†é‡å®šå‘: %s", location)

	scheme := getRequestScheme(r)
	tm := auth.GetGlobalTokenManager()
	tokenParam := "token"
	if tm != nil && tm.TokenParamName != "" {
		tokenParam = tm.TokenParamName
	}

	newLocation := location

	if strings.HasPrefix(location, "http://") || strings.HasPrefix(location, "https://") {
		baseURL := fmt.Sprintf("%s://%s", scheme, r.Host)
		newLocation = joinBaseWithFullURL(baseURL, location)
	} else {
		// ç›¸å¯¹è·¯å¾„
		newLocation = fmt.Sprintf("%s://%s/%s", scheme, r.Host, strings.TrimLeft(location, "/"))
	}

	// æ·»åŠ  token æ˜æ–‡
	if tm != nil && tm.Enabled {
		if !strings.Contains(newLocation, tokenParam+"=") {
			token := generateToken(tm, location)
			if token != "" {
				if strings.Contains(newLocation, "?") {
					newLocation += "&" + tokenParam + "=" + token
				} else {
					newLocation += "?" + tokenParam + "=" + token
				}
			}
		}
	}

	logger.LogPrintf("é‡å®šå‘åˆ°: %s", newLocation)
	w.Header().Set("Location", newLocation)
	w.WriteHeader(proxyResp.StatusCode)
}

// handleSpecialContent å¤„ç† m3u8 æ–‡ä»¶å†…å®¹
func handleSpecialContent(w http.ResponseWriter, r *http.Request, proxyResp *http.Response, buf []byte) {
	// defer proxyResp.Body.Close()

	bufSize := len(buf)
	reader := bufio.NewReaderSize(proxyResp.Body, bufSize)

	scheme := getRequestScheme(r)
	baseURL := fmt.Sprintf("%s://%s", scheme, r.Host)

	tm := auth.GetGlobalTokenManager()
	tokenParam := "token"
	if tm != nil && tm.TokenParamName != "" {
		tokenParam = tm.TokenParamName
	}

	seen := make(map[string]struct{})
	var resultLines []string

	for {
		line, err := reader.ReadString('\n')
		if err != nil && !errors.Is(err, io.EOF) {
			http.Error(w, "è¯»å–å“åº”å†…å®¹å¤±è´¥", http.StatusInternalServerError)
			return
		}

		line = strings.TrimSpace(line)
		if line == "" {
			if err == io.EOF {
				break
			}
			continue
		}

		// --- å¤„ç† EXT æ ‡ç­¾ ---
		if strings.HasPrefix(line, "#") {
			if strings.Contains(line, "URI=\"") {
				re := regexp.MustCompile(`URI="([^"]+)"`)
				line = re.ReplaceAllStringFunc(line, func(match string) string {
					uri := re.FindStringSubmatch(match)[1]
					newURI := uri
					token := ""
					if tm != nil && tm.Enabled {
						token = generateToken(tm, uri)
					}
					if token != "" {
						if strings.Contains(newURI, "?") {
							newURI += "&" + tokenParam + "=" + token
						} else {
							newURI += "?" + tokenParam + "=" + token
						}
					}
					return fmt.Sprintf(`URI="%s"`, newURI)
				})
			}
			resultLines = append(resultLines, line)
			if err == io.EOF {
				break
			}
			continue
		}

		// --- æ™®é€šè¡Œ (TS/URL) ---
		newLine := line
		token := ""
		if tm != nil && tm.Enabled {
			token = generateToken(tm, line)
		}
		if token != "" {
			if strings.Contains(newLine, "?") {
				newLine += "&" + tokenParam + "=" + token
			} else {
				newLine += "?" + tokenParam + "=" + token
			}
		}

		// å»é‡
		if _, exists := seen[newLine]; exists {
			if err == io.EOF {
				break
			}
			continue
		}
		seen[newLine] = struct{}{}

		// âœ… åªæœ‰ http/https æ—¶æ‰æ‹¼æ¥ baseURL
		if strings.HasPrefix(newLine, "http://") || strings.HasPrefix(newLine, "https://") {
			newLine = joinBaseWithFullURL(baseURL, newLine)
		}

		resultLines = append(resultLines, newLine)

		if err == io.EOF {
			break
		}
	}

	// æ‹¼æ¥ç»“æœ
	result := strings.Join(resultLines, "\n") + "\n"

	CopyHeader(w.Header(), proxyResp.Header, r.ProtoMajor)
	w.Header().Del("Content-Length")
	w.WriteHeader(proxyResp.StatusCode)
	_, _ = w.Write([]byte(result))
}

// joinBaseWithFullURL æ‹¼æ¥ baseURL å’Œå®Œæ•´ URLï¼Œä¸åšä»»ä½• encode
func joinBaseWithFullURL(baseURL, fullURL string) string {
	baseURL = strings.TrimRight(baseURL, "/")
	fullURL = strings.TrimLeft(fullURL, "/")
	return baseURL + "/" + fullURL
}

// generateToken æ˜æ–‡ç”Ÿæˆ tokenï¼ˆåŠ¨æ€æˆ–é™æ€ï¼‰
func generateToken(tm *auth.TokenManager, path string) string {
	if tm == nil || !tm.Enabled {
		return ""
	}
	if tm.DynamicTokens != nil {
		if tok, err := tm.GenerateDynamicToken(path); err == nil && tok != "" {
			return tok
		}
	}
	if len(tm.StaticTokens) > 0 {
		for st := range tm.StaticTokens {
			return st
		}
	}
	return ""
}

// CopyResponse æ ¹æ®å†…å®¹ç±»å‹é€‰æ‹©é€‚å½“çš„å¤åˆ¶æ–¹æ³•
func CopyResponse(
	ctx context.Context,
	w http.ResponseWriter,
	r *http.Request,
	resp *http.Response,
	targetURL string,
	buf []byte,
	bufSize int,
	updateActive func(),
	statusCode int,
) error {
	u, err := url.Parse(targetURL)
	if err != nil {
		return err
	}

	contentType := resp.Header.Get("Content-Type")
	isTS := strings.EqualFold(filepath.Ext(u.Path), ".ts")

	// TS è¯·æ±‚æå‰æ¸…ç†å¤´
	if isTS {
		w.Header().Del("Content-Length")
	}

	// ğŸ”´ å…³é—­çŠ¶æ€ï¼šå…¨éƒ¨é€€åŒ–ä¸º Copytext
	if !isStreamFeatureEnabled() {
		// logger.LogPrintf(
		// 	"stream disabled, fallback to Copytext: %s",
		// 	u.Path,
		// )
		return Copytext(ctx, w, resp.Body, buf, updateActive)
	}

	// ğŸŸ¢ æ­£å¸¸é€»è¾‘
	if isWebPageContent(contentType, u.Path) {
		return Copytext(ctx, w, resp.Body, buf, updateActive)
	}

	return CopyWithContext(
		ctx,
		w,
		resp.Body,
		buf,
		bufSize,
		updateActive,
		resp.Request.URL.String(),
		statusCode,
	)
}


func isStreamFeatureEnabled() bool {
	// TSCache æ˜¯ä½ æµåª’ä½“ / FCC / Hub çš„â€œæ€»å¼€å…³ä¿¡å·â€
	return GlobalTSCache != nil
}
