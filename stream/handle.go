package stream

import (
	"bufio"
	"context"
	"errors"
	"fmt"
	"net"
	"time"

	"github.com/qist/tvgate/auth"
	"github.com/qist/tvgate/logger"

	// "github.com/qist/tvgate/monitor"
	"io"
	"net/http"
	"net/url"
	"path/filepath"
	"regexp"
	"strings"
	"sync"

	"github.com/qist/tvgate/utils/buffer"
)

// å®šä¹‰ä»»åŠ¡ç»“æ„ä½“ç”¨äºsync.Pool
type handleTask struct {
	f func()
}

// åˆ›å»ºsync.Poolç”¨äºå¤ç”¨ä»»åŠ¡å¯¹è±¡
var handleTaskPool = sync.Pool{
	New: func() interface{} {
		return &handleTask{}
	},
}

// ç»Ÿä¸€å¤„ç†å“åº”ï¼ˆé‡å®šå‘ã€ç‰¹æ®Šç±»å‹ã€æ™®é€šå†…å®¹ï¼‰
func HandleProxyResponse(ctx context.Context, w http.ResponseWriter, r *http.Request, targetURL string, resp *http.Response, updateActive func()) {
	defer func() {
		if err := resp.Body.Close(); err != nil {
			logger.LogPrintf("å…³é—­å“åº”ä½“é”™è¯¯: %v", err)
		}
	}()

	logger.LogRequestAndResponse(r, targetURL, resp) // æ—¥å¿—è®°å½•

	contentType := resp.Header.Get("Content-Type")

	switch resp.StatusCode {
	case http.StatusMovedPermanently, http.StatusFound, http.StatusTemporaryRedirect:
		handleRedirect(w, r, resp)
		return
	}

	if IsSupportedContentType(contentType) {
		handleSpecialContent(w, r, resp, nil) // è¿™é‡Œä¸éœ€è¦bufï¼Œå› ä¸ºhandleSpecialContentå†…éƒ¨ä¼šè‡ªå·±è·å–
		return
	}

	// æ£€æŸ¥æ˜¯å¦ä¸ºTSè¯·æ±‚ï¼Œå¦‚æœæ˜¯ï¼Œéœ€è¦æå‰æ¸…ç†å¯èƒ½çš„é—®é¢˜å¤´éƒ¨
	u, err := url.Parse(targetURL)
	if err != nil {
		logger.LogPrintf("è§£æç›®æ ‡URLå¤±è´¥: %v", err)
		return
	}

	// if strings.EqualFold(filepath.Ext(u.Path), ".ts") {
	// åˆ é™¤å¯èƒ½å¼•èµ·é—®é¢˜çš„å¤´éƒ¨ï¼Œç‰¹åˆ«æ˜¯Content-Length
	// è¿™å¿…é¡»åœ¨å†™å…¥ä»»ä½•å“åº”æ•°æ®ä¹‹å‰å®Œæˆ
	resp.Header.Del("Content-Length")
	// }

	// å¤åˆ¶å“åº”å¤´
	CopyHeader(w.Header(), resp.Header, r.ProtoMajor)
	w.Header().Del("Content-Length")
	w.WriteHeader(resp.StatusCode)

	// è§£æURLå¹¶è·å–æœ€ä¼˜ç¼“å†²åŒºå¤§å°
	bufSize := buffer.GetOptimalBufferSize(contentType, u.Path)
	buf := buffer.GetBuffer(bufSize)
	defer buffer.PutBuffer(bufSize, buf)

	// ä½¿ç”¨ç»Ÿä¸€çš„å“åº”å¤åˆ¶å‡½æ•°
	copyFunc := func() error {
		return CopyResponse(ctx, w, r, resp, targetURL, buf, bufSize, updateActive, resp.StatusCode)
	}

	// ä½¿ç”¨ç»Ÿä¸€çš„æ‰§è¡Œå‡½æ•°å¤„ç†å¤åˆ¶æ“ä½œ
	executeCopyWithPool(ctx, r, targetURL, copyFunc, resp)
}

// executeCopyWithPool ä½¿ç”¨ä»»åŠ¡æ± æ‰§è¡Œå¤åˆ¶æ“ä½œ
func executeCopyWithPool(ctx context.Context, r *http.Request, targetURL string, copyFunc func() error, resp *http.Response) {
	done := make(chan struct{})

	// ä»æ± ä¸­è·å–ä»»åŠ¡å¯¹è±¡
	task := handleTaskPool.Get().(*handleTask)
	task.f = func() {
		defer close(done)
		if err := copyFunc(); err != nil {
			HandleCopyError(r, err, resp)
		}
	}

	// åœ¨goroutineå†…éƒ¨æ‰§è¡Œä»»åŠ¡å¹¶ç¡®ä¿å®Œæˆåæ”¾å›æ± ä¸­
	go func() {
		defer func() {
			// æ¸…ç©ºä»»åŠ¡å¹¶æ”¾å›æ± ä¸­
			task.f = nil
			handleTaskPool.Put(task)
		}()
		task.f()
	}()

	select {
	case <-ctx.Done():
		logger.LogPrintf("å®¢æˆ·ç«¯æ–­å¼€è¿æ¥: %s", targetURL)
	case <-done:
		logger.LogPrintf("å“åº”æˆåŠŸå®Œæˆ: %s", targetURL)
	}
}

// Copytext æµå¼å¤åˆ¶ src -> dstï¼Œä½¿ç”¨ buffer æ± ï¼Œbufio å†…éƒ¨ç¼“å­˜å¯æ§
func Copytext(ctx context.Context, dst io.Writer, src io.Reader, buf []byte, updateActive func()) error {
	// æ´»è·ƒæ—¶é—´å¿ƒè·³
	var activeTicker *time.Ticker
	if updateActive != nil {
		activeTicker = time.NewTicker(5 * time.Second)
		defer activeTicker.Stop()
		defer updateActive() // é€€å‡ºå‰æ›´æ–°ä¸€æ¬¡
	}

	// flush å®šæ—¶å™¨ï¼ˆé™ä½å»¶è¿Ÿï¼‰
	flushTicker := time.NewTicker(200 * time.Millisecond)
	defer flushTicker.Stop()

	// æ˜¯å¦æ”¯æŒ http flush
	flusher, canFlush := dst.(http.Flusher)

	// ç»Ÿè®¡å†™å…¥å­—èŠ‚æ•°
	bytesWritten := 0

	// å¦‚æœ src æ˜¯ net.Connï¼Œç»™å®ƒç»‘ ctx
	if c, ok := src.(net.Conn); ok {
		go func() {
			<-ctx.Done()
			// æ‰“æ–­é˜»å¡ read
			_ = c.SetReadDeadline(time.Now())
		}()
	}

	for {
		// è¯»å–æ•°æ®
		n, readErr := src.Read(buf)
		if n > 0 {
			// monitor.AddAppInboundBytes(uint64(n))
			written := 0
			for written < n {
				wn, writeErr := dst.Write(buf[written:n])
				if writeErr != nil {
					return fmt.Errorf("å†™å…¥é”™è¯¯: %w", writeErr)
				}
				written += wn
				bytesWritten += wn
			}
			// monitor.AddAppOutboundBytes(uint64(n))

			// å¤§æ•°æ®é‡è§¦å‘ flush
			if canFlush && bytesWritten >= 32*1024 {
				flusher.Flush()
				bytesWritten = 0
			}
		}

		// é”™è¯¯å¤„ç†
		if readErr != nil {
			if canFlush && bytesWritten > 0 {
				flusher.Flush()
			}
			if errors.Is(readErr, io.EOF) {
				return nil
			}
			return fmt.Errorf("è¯»å–é”™è¯¯: %w", readErr)
		}

		// éé˜»å¡æ£€æŸ¥ ctx / ticker
		select {
		case <-ctx.Done():
			return ctx.Err()
		case <-flushTicker.C:
			if canFlush && bytesWritten > 0 {
				flusher.Flush()
				bytesWritten = 0
			}
		case <-activeTicker.C:
			if updateActive != nil {
				updateActive()
			}
		default:
		}
	}
}

// getRequestScheme è¿”å›å®¢æˆ·ç«¯çœŸå®ä½¿ç”¨çš„åè®® (http/https)
func getRequestScheme(r *http.Request) string {
	// 1. å…ˆçœ‹æ ‡å‡†å¤´
	if proto := r.Header.Get("X-Forwarded-Proto"); proto != "" {
		return proto
	}

	// 2. Cloudflare ä¸“ç”¨å¤´
	if cfVisitor := r.Header.Get("CF-Visitor"); strings.Contains(cfVisitor, "https") {
		return "https"
	}

	// 3. æ ‡å‡† Forwarded å¤´
	if forwarded := r.Header.Get("Forwarded"); strings.Contains(forwarded, "proto=https") {
		return "https"
	}

	// 4. æ²¡æœ‰ä»£ç†å¤´å°±çœ‹åç«¯æ˜¯å¦å¯ç”¨ TLS
	if r.TLS != nil {
		return "https"
	}

	return "http"
}

// æ”¯æŒçš„å†…å®¹ç±»å‹åˆ—è¡¨
var supportedContentTypes = []string{
	"application/vnd.apple.mpegurl",
	"application/x-mpegurl",
	"audio/mpegurl",
	"audio/x-mpegurl",
	"application/mpegurl",
}

// æ£€æŸ¥å†…å®¹ç±»å‹æ˜¯å¦å—æ”¯æŒ
func IsSupportedContentType(contentType string) bool {
	contentType = strings.ToLower(contentType)
	for _, t := range supportedContentTypes {
		if strings.HasPrefix(contentType, strings.ToLower(t)) {
			return true
		}
	}
	return false
}

// getTargetPath è·å–ç›®æ ‡è·¯å¾„
func GetTargetPath(r *http.Request) string {
	return r.URL.Path[1:] // å»é™¤å¼€å¤´çš„ /
}

// getTargetURL è·å–å®Œæ•´çš„ç›®æ ‡URL
func GetTargetURL(r *http.Request, targetPath string) string {
	// åˆ†ç¦»è·¯å¾„å’ŒæŸ¥è¯¢å‚æ•°
	pathAndQuery := strings.SplitN(targetPath, "?", 2)
	path := pathAndQuery[0]
	var query string
	if len(pathAndQuery) > 1 {
		query = "?" + pathAndQuery[1]
	}

	// å¤„ç†URLè·¯å¾„éƒ¨åˆ†
	if strings.HasPrefix(path, "http:/") && !strings.HasPrefix(path, "http://") {
		path = "http://" + strings.TrimPrefix(path, "http:/")
	} else if strings.HasPrefix(path, "https:/") && !strings.HasPrefix(path, "https://") {
		path = "https://" + strings.TrimPrefix(path, "https:/")
	} else if !strings.HasPrefix(path, "http://") && !strings.HasPrefix(path, "https://") {
		path = "http://" + path
	}

	// é‡æ–°ç»„åˆè·¯å¾„å’ŒæŸ¥è¯¢å‚æ•°
	targetURL := path + query

	// ä¿ç•™åŸå§‹è¯·æ±‚ä¸­çš„æŸ¥è¯¢å‚æ•°
	if r.URL.RawQuery != "" {
		if strings.Contains(targetURL, "?") {
			targetURL += "&" + r.URL.RawQuery
		} else {
			targetURL += "?" + r.URL.RawQuery
		}
	}
	//logger.LogPrintf("getTargetURL å¤„ç†: åŸå§‹è·¯å¾„=%s, æŸ¥è¯¢å‚æ•°=%s, æœ€ç»ˆURL=%s",
	//	path, r.URL.RawQuery, targetURL)

	return targetURL
}

// CopyWithContext æ”¯æŒ HTTP hub æ¨¡å¼ï¼šæŒ‰åç«¯URLä¸ºé”®ï¼Œå•ä¸Šæ¸¸å¹¿æ’­åˆ°æ‰€æœ‰å‰ç«¯
func CopyWithContext(
	ctx context.Context,
	dst http.ResponseWriter,
	src io.Reader,
	buf []byte,
	bufSize int,
	updateActive func(),
	backendKey string,
) error {
	h := GetOrCreateHTTPHub(backendKey)

	client := h.AddClient(dst, bufSize)
	defer h.RemoveClient(client)

	h.EnsureProducer(ctx, src, buf)
	return client.WriteLoop(ctx, updateActive)
}

// CopyTSWithCache å¤„ç† TS æµç¼“å­˜è¯»å–æˆ–ä»æºè¯»å–å†™å…¥å“åº”
func CopyTSWithCache(ctx context.Context, dst http.ResponseWriter, src io.Reader, key string) error {
	cacheItem, ok := GlobalTSCache.Get(key)
	if ok {
		logger.LogPrintf("[TSç¼“å­˜] å‘½ä¸­ï¼Œkey: %s", key)
		done := make(chan struct{})
		defer close(done)

		dst.Header().Del("Content-Length")
		if err := cacheItem.ReadAll(dst, done); err != nil && err != io.EOF && err != io.ErrNoProgress {
			logger.LogPrintf("[TSç¼“å­˜] è¯»å–å‡ºé”™: %v, key: %s", err, key)
		}

		if f, ok := dst.(http.Flusher); ok {
			f.Flush()
		}
		return nil
	}

	logger.LogPrintf("[TSç¼“å­˜] æœªå‘½ä¸­ï¼Œå¼€å§‹ä¸‹è½½å¹¶ç¼“å­˜ï¼Œkey: %s", key)
	// åˆ›å»ºå¸¦è¶…æ—¶çš„ä¸Šä¸‹æ–‡
	timeoutCtx, cancel := context.WithTimeout(ctx, 45*time.Second)
	defer cancel()

	resultChan := make(chan struct {
		err error
	}, 1)

	// singleflight ç¡®ä¿åŒ key åªæ‹‰ä¸€æ¬¡æºï¼Œä½†ä½¿ç”¨ goroutine é¿å…é˜»å¡
	go func() {
		_, err, shared := GlobalTSCache.sf.Do(key, func() (interface{}, error) {
			cacheItem, created := GlobalTSCache.GetOrCreate(key)
			if !created {
				return nil, nil
			}

			dst.Header().Del("Content-Length")
			buf := make([]byte, 32*1024)

			for {
				n, rErr := src.Read(buf)
				if n > 0 {
					chunk := make([]byte, n)
					copy(chunk, buf[:n])

					GlobalTSCache.WriteChunkWithByteTracking(cacheItem, chunk)

					written, wErr := dst.Write(chunk)
					if wErr != nil {
						cacheItem.Close()
						return nil, wErr
					}
					if written != n {
						cacheItem.Close()
						return nil, io.ErrShortWrite
					}

					if f, ok := dst.(http.Flusher); ok {
						f.Flush()
					}
				}

				if rErr != nil {
					if rErr == io.EOF {
						return nil, nil
					}
					cacheItem.Close()
					return nil, rErr
				}
			}
		})

		if shared {
			resultChan <- struct{ err error }{err: nil}
		} else {
			resultChan <- struct{ err error }{err: err}
		}
	}()

	select {
	case <-timeoutCtx.Done():
		logger.LogPrintf("TSä¸‹è½½è¶…æ—¶ï¼Œkey: %s", key)
		GlobalTSCache.Remove(key)
		return timeoutCtx.Err()
	case result := <-resultChan:
		return result.err
	}
}

func HandleCopyError(r *http.Request, err error, proxyResp *http.Response) {
	if errors.Is(err, context.Canceled) {
		logger.LogPrintf("ä¼ è¾“è¢«å–æ¶ˆ: %v, URL: %s", err, proxyResp.Request.URL.String())
	} else if errors.Is(err, context.DeadlineExceeded) {
		logger.LogPrintf("ä¼ è¾“è¶…æ—¶: %v, URL: %s", err, proxyResp.Request.URL.String())
	} else {
		logger.LogPrintf("[%s] å‰ç«¯å…³é—­è¿æ¥ %s", r.RemoteAddr, proxyResp.Request.URL.String())
	}

	// å¯é€‰ï¼šå‘å®¢æˆ·ç«¯è¿”å›é”™è¯¯
	// if w.Header().Get("Content-Length") == "" {
	// 	http.Error(w, "æœåŠ¡å™¨é”™è¯¯", http.StatusInternalServerError)
	// }
}

// copyHeadersExceptSensitive å¤åˆ¶ HTTP å¤´éƒ¨ï¼Œè·³è¿‡æ•æ„Ÿæˆ–ç‰¹æ®Šå¤´éƒ¨
func CopyHeadersExceptSensitive(dst http.Header, src http.Header, protoMajor int) {
	for k, vv := range src {
		lowerKey := strings.ToLower(k)
		// è·³è¿‡ä¸å…¼å®¹å¤´
		switch lowerKey {
		case "connection", "proxy-connection", "keep-alive",
			"transfer-encoding", "upgrade", "te", "trailer", "trailers":
			continue
		}
		// å¦‚æœæ˜¯ HTTP/2ï¼Œä¸å…è®¸ keep-alive ä¹‹ç±»
		if protoMajor == 2 && (lowerKey == "keep-alive" || lowerKey == "connection") {
			continue
		}
		for _, v := range vv {
			dst.Add(k, v)
		}
	}
}

// copyHeader å¤åˆ¶ HTTP å¤´éƒ¨ï¼ŒæŒ‰åè®®ç‰ˆæœ¬è¿‡æ»¤ä¸å…¼å®¹å­—æ®µ
// - dst: ç›®æ ‡ Headerï¼ˆå®¢æˆ·ç«¯æˆ–åç«¯ï¼‰
// - src: æ¥æº Headerï¼ˆåç«¯å“åº”æˆ–å®¢æˆ·ç«¯è¯·æ±‚ï¼‰
// - protoMajor: å®¢æˆ·ç«¯ä½¿ç”¨çš„åè®®ç‰ˆæœ¬ï¼Œ1 = HTTP/1.x, 2 = HTTP/2
func CopyHeader(dst, src http.Header, protoMajor int) {
	for k, vv := range src {
		lowerKey := strings.ToLower(k)

		// æ°¸è¿œä¸åº”è¯¥é€ä¼ çš„å¤´
		switch lowerKey {
		case "host", "proxy-authorization", "proxy-connection":
			continue
		}

		// HTTP/2 ä¸å…è®¸çš„å¤´
		if protoMajor == 2 {
			switch lowerKey {
			case "connection", "keep-alive", "transfer-encoding",
				"upgrade", "te", "trailer", "trailers":
				continue
			}
		}

		// å¤åˆ¶å‰©ä½™å¤´
		for _, v := range vv {
			dst.Add(k, v)
		}
	}
}

// handleRedirect å¤„ç† HTTP 301/302 é‡å®šå‘
func handleRedirect(w http.ResponseWriter, r *http.Request, proxyResp *http.Response) {
	location := proxyResp.Header.Get("Location")
	if location == "" {
		w.WriteHeader(proxyResp.StatusCode)
		return
	}

	logger.LogPrintf("å¤„ç†é‡å®šå‘: %s", location)

	scheme := getRequestScheme(r)
	tm := auth.GetGlobalTokenManager()
	tokenParam := "token"
	if tm != nil && tm.TokenParamName != "" {
		tokenParam = tm.TokenParamName
	}

	newLocation := location

	if strings.HasPrefix(location, "http://") || strings.HasPrefix(location, "https://") {
		baseURL := fmt.Sprintf("%s://%s", scheme, r.Host)
		newLocation = joinBaseWithFullURL(baseURL, location)
	} else {
		// ç›¸å¯¹è·¯å¾„
		newLocation = fmt.Sprintf("%s://%s/%s", scheme, r.Host, strings.TrimLeft(location, "/"))
	}

	// æ·»åŠ  token æ˜æ–‡
	if tm != nil && tm.Enabled {
		if !strings.Contains(newLocation, tokenParam+"=") {
			token := generateToken(tm, location)
			if token != "" {
				if strings.Contains(newLocation, "?") {
					newLocation += "&" + tokenParam + "=" + token
				} else {
					newLocation += "?" + tokenParam + "=" + token
				}
			}
		}
	}

	logger.LogPrintf("é‡å®šå‘åˆ°: %s", newLocation)
	w.Header().Set("Location", newLocation)
	w.WriteHeader(proxyResp.StatusCode)
}

// handleSpecialContent å¤„ç† m3u8 æ–‡ä»¶å†…å®¹
func handleSpecialContent(w http.ResponseWriter, r *http.Request, proxyResp *http.Response, buf []byte) {
	// defer proxyResp.Body.Close()

	bufSize := len(buf)
	reader := bufio.NewReaderSize(proxyResp.Body, bufSize)

	scheme := getRequestScheme(r)
	baseURL := fmt.Sprintf("%s://%s", scheme, r.Host)

	tm := auth.GetGlobalTokenManager()
	tokenParam := "token"
	if tm != nil && tm.TokenParamName != "" {
		tokenParam = tm.TokenParamName
	}

	seen := make(map[string]struct{})
	var resultLines []string

	for {
		line, err := reader.ReadString('\n')
		if err != nil && !errors.Is(err, io.EOF) {
			http.Error(w, "è¯»å–å“åº”å†…å®¹å¤±è´¥", http.StatusInternalServerError)
			return
		}

		line = strings.TrimSpace(line)
		if line == "" {
			if err == io.EOF {
				break
			}
			continue
		}

		// --- å¤„ç† EXT æ ‡ç­¾ ---
		if strings.HasPrefix(line, "#") {
			if strings.Contains(line, "URI=\"") {
				re := regexp.MustCompile(`URI="([^"]+)"`)
				line = re.ReplaceAllStringFunc(line, func(match string) string {
					uri := re.FindStringSubmatch(match)[1]
					newURI := uri
					token := ""
					if tm != nil && tm.Enabled {
						token = generateToken(tm, uri)
					}
					if token != "" {
						if strings.Contains(newURI, "?") {
							newURI += "&" + tokenParam + "=" + token
						} else {
							newURI += "?" + tokenParam + "=" + token
						}
					}
					return fmt.Sprintf(`URI="%s"`, newURI)
				})
			}
			resultLines = append(resultLines, line)
			if err == io.EOF {
				break
			}
			continue
		}

		// --- æ™®é€šè¡Œ (TS/URL) ---
		newLine := line
		token := ""
		if tm != nil && tm.Enabled {
			token = generateToken(tm, line)
		}
		if token != "" {
			if strings.Contains(newLine, "?") {
				newLine += "&" + tokenParam + "=" + token
			} else {
				newLine += "?" + tokenParam + "=" + token
			}
		}

		// å»é‡
		if _, exists := seen[newLine]; exists {
			if err == io.EOF {
				break
			}
			continue
		}
		seen[newLine] = struct{}{}

		// âœ… åªæœ‰ http/https æ—¶æ‰æ‹¼æ¥ baseURL
		if strings.HasPrefix(newLine, "http://") || strings.HasPrefix(newLine, "https://") {
			newLine = joinBaseWithFullURL(baseURL, newLine)
		}

		resultLines = append(resultLines, newLine)

		if err == io.EOF {
			break
		}
	}

	// æ‹¼æ¥ç»“æœ
	result := strings.Join(resultLines, "\n") + "\n"

	CopyHeader(w.Header(), proxyResp.Header, r.ProtoMajor)
	w.Header().Del("Content-Length")
	w.WriteHeader(proxyResp.StatusCode)
	_, _ = w.Write([]byte(result))
}

// joinBaseWithFullURL æ‹¼æ¥ baseURL å’Œå®Œæ•´ URLï¼Œä¸åšä»»ä½• encode
func joinBaseWithFullURL(baseURL, fullURL string) string {
	baseURL = strings.TrimRight(baseURL, "/")
	fullURL = strings.TrimLeft(fullURL, "/")
	return baseURL + "/" + fullURL
}

// generateToken æ˜æ–‡ç”Ÿæˆ tokenï¼ˆåŠ¨æ€æˆ–é™æ€ï¼‰
func generateToken(tm *auth.TokenManager, path string) string {
	if tm == nil || !tm.Enabled {
		return ""
	}
	if tm.DynamicTokens != nil {
		if tok, err := tm.GenerateDynamicToken(path); err == nil && tok != "" {
			return tok
		}
	}
	if len(tm.StaticTokens) > 0 {
		for st := range tm.StaticTokens {
			return st
		}
	}
	return ""
}

// CopyResponse æ ¹æ®å†…å®¹ç±»å‹é€‰æ‹©é€‚å½“çš„å¤åˆ¶æ–¹æ³•
func CopyResponse(
	ctx context.Context,
	w http.ResponseWriter,
	r *http.Request,
	resp *http.Response,
	targetURL string,
	buf []byte,
	bufSize int,
	updateActive func(),
	statusCode int,
) error {
	u, err := url.Parse(targetURL)
	if err != nil {
		return err
	}

	// TS è¯·æ±‚æå‰æ¸…ç†å¤´
	// if isTS {
	w.Header().Del("Content-Length")
	// }

	// ğŸ”´ å…³é—­çŠ¶æ€ï¼šå…¨éƒ¨é€€åŒ–ä¸º Copytext
	if !isStreamFeatureEnabled() {
		return Copytext(ctx, w, resp.Body, buf, updateActive)
	}

	if IsTSRequest(u.Path) {
		key := normalizeCacheKey(u.Path)
		logger.LogPrintf("[TSç¼“å­˜] ç”Ÿæˆç¼“å­˜é”®ï¼Œkey: %s", key)
		return CopyTSWithCache(ctx, w, resp.Body, key)
	}

	if isLiveStream(u.Path) {
		return CopyWithContext(
			ctx,
			w,
			resp.Body,
			buf,
			bufSize,
			updateActive,
			resp.Request.URL.String(),
		)
	}
	return Copytext(ctx, w, resp.Body, buf, updateActive)
}

func isStreamFeatureEnabled() bool {
	// TSCache æ˜¯ä½ æµåª’ä½“ / FCC / Hub çš„â€œæ€»å¼€å…³ä¿¡å·â€
	return GlobalTSCache != nil
}

// isLiveStream åˆ¤æ–­æ˜¯å¦æ˜¯ç›´æ’­æµ
func isLiveStream(path string) bool {
	p := strings.ToLower(path)

	// è§£æURLä»¥æ­£ç¡®æå–è·¯å¾„éƒ¨åˆ†ï¼Œå»é™¤æŸ¥è¯¢å‚æ•°å’Œç‰‡æ®µ
	if u, err := url.Parse(p); err == nil {
		p = strings.ToLower(u.Path)
	}

	// ===== UDP / RTP æµ =====
	// if strings.Contains(p, "/udp/") || strings.Contains(p, "/rtp/") {
	// 	return true
	// }

	// ===== FLV ç›´æ’­æµ =====
	if strings.HasSuffix(p, ".flv") {
		// å¦‚æœ URL å¸¦ live æˆ– hub ç‰¹å¾ï¼Œåˆ¤å®šä¸ºç›´æ’­
		return true
	}
	// å…¶ä»–éƒ½ä¸æ˜¯æµåª’ä½“
	return false
}

func IsTSRequest(rawURL string) bool {
	u, err := url.Parse(rawURL)
	if err != nil {
		// è§£æå¤±è´¥æ—¶å…œåº•
		return strings.EqualFold(filepath.Ext(rawURL), ".ts")
	}

	// åªçœ‹ pathï¼Œä¸çœ‹ query / fragment
	return strings.EqualFold(filepath.Ext(u.Path), ".ts")
}

// normalizeCacheKey ç”Ÿæˆç›´è§‚çš„ç¼“å­˜é”®
func normalizeCacheKey(rawURL string) string {
	u, err := url.Parse(rawURL)
	if err != nil {
		return rawURL
	}

	// 1ï¸âƒ£ å» query å’Œ fragment
	u.RawQuery = ""
	u.Fragment = ""

	path := u.Path

	// 2ï¸âƒ£ è¯†åˆ«è·¯å¾„ä¸­åµŒå¥—çš„çœŸå®åŸŸåï¼ˆCDN å›æºæ ¼å¼ï¼‰
	// å…¸å‹æ ¼å¼ï¼š/token/real.domain.com/xxxx/xxxx.ts
	parts := strings.Split(path, "/")

	for i, p := range parts {
		// æ‰¾åˆ°åƒåŸŸåçš„é‚£ä¸€æ®µ
		if strings.Contains(p, ".") && !strings.Contains(p, ":") {
			// ä»è¿™é‡Œå¼€å§‹æ‰æ˜¯çœŸè·¯å¾„
			realHost := p
			realPath := "/" + strings.Join(parts[i+1:], "/")
			return realHost + realPath
		}
	}

	// æ™®é€š URLï¼ˆæ²¡æœ‰åµŒå¥—åŸŸåï¼‰
	return u.String()
}
